{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mpld3 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (0.5.2)\n",
      "Requirement already satisfied: matplotlib in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from mpld3) (3.3.3)\n",
      "Requirement already satisfied: jinja2 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from mpld3) (2.11.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from matplotlib->mpld3) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from matplotlib->mpld3) (8.0.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from matplotlib->mpld3) (1.19.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from matplotlib->mpld3) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from matplotlib->mpld3) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from matplotlib->mpld3) (0.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from jinja2->mpld3) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib->mpld3) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mpld3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (4.14.1)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from plotly) (1.3.3)\n",
      "Requirement already satisfied: six in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from plotly) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# keeps the plots in one place. calls image as static pngs\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt # side-stepping mpl backend\n",
    "import matplotlib.gridspec as gridspec # subplots\n",
    "import mpld3 as mpl\n",
    "\n",
    "#Import models from scikit learn module:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import metrics\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import plotly.figure_factory as ff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='EURCHF.csv'\n",
    "df = pd.read_csv(file, na_values='n/a', parse_dates=[0], index_col = [0], usecols=[2,3,4], names=[\"date\", \"time\", \"close\"], header=0)\n",
    "# Mask for specific TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>2130</td>\n",
       "      <td>1.10179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>2200</td>\n",
       "      <td>1.10202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>2230</td>\n",
       "      <td>1.10232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>2300</td>\n",
       "      <td>1.10150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.10198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-19</th>\n",
       "      <td>2230</td>\n",
       "      <td>1.06487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-19</th>\n",
       "      <td>2300</td>\n",
       "      <td>1.06487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-19</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.06468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-20</th>\n",
       "      <td>0</td>\n",
       "      <td>1.06427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-20</th>\n",
       "      <td>30</td>\n",
       "      <td>1.06430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7231 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            time    close\n",
       "date                     \n",
       "2019-12-01  2130  1.10179\n",
       "2019-12-01  2200  1.10202\n",
       "2019-12-01  2230  1.10232\n",
       "2019-12-01  2300  1.10150\n",
       "2019-12-01  2330  1.10198\n",
       "...          ...      ...\n",
       "2020-06-19  2230  1.06487\n",
       "2020-06-19  2300  1.06487\n",
       "2020-06-19  2330  1.06468\n",
       "2020-06-20     0  1.06427\n",
       "2020-06-20    30  1.06430\n",
       "\n",
       "[7231 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EUR/CHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='EURCHF.csv'\n",
    "df = pd.read_csv(file, na_values='n/a', parse_dates=[0], index_col = [0], usecols=[2,3,4], names=[\"date\", \"time\", \"close\"], header=0)\n",
    "# Mask for specific TIME\n",
    "time_1830 = df.time == 1830\n",
    "time_2200 = df.time == 2330\n",
    "\n",
    "# Filter using the mask\n",
    "df1=df.loc[time_1830]\n",
    "df2=df.loc[time_2200]\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = df.sort_values(['date','time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.10198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02</th>\n",
       "      <td>1830</td>\n",
       "      <td>1.10014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.09859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03</th>\n",
       "      <td>1830</td>\n",
       "      <td>1.09362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.09390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-17</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.06647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-18</th>\n",
       "      <td>1830</td>\n",
       "      <td>1.06655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-18</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.06624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-19</th>\n",
       "      <td>1830</td>\n",
       "      <td>1.06504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-19</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.06468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            time    close\n",
       "date                     \n",
       "2019-12-01  2330  1.10198\n",
       "2019-12-02  1830  1.10014\n",
       "2019-12-02  2330  1.09859\n",
       "2019-12-03  1830  1.09362\n",
       "2019-12-03  2330  1.09390\n",
       "...          ...      ...\n",
       "2020-06-17  2330  1.06647\n",
       "2020-06-18  1830  1.06655\n",
       "2020-06-18  2330  1.06624\n",
       "2020-06-19  1830  1.06504\n",
       "2020-06-19  2330  1.06468\n",
       "\n",
       "[318 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime class from datetime module\n",
    "from datetime import datetime\n",
    "# import calendar module\n",
    "import calendar\n",
    "# Use pandas' get_dummies function to get dummies for day of the week\n",
    "days_of_week = pd.get_dummies(df.index.dayofweek,\n",
    "                              prefix='weekday',\n",
    "                              drop_first=True)\n",
    "# Set the index as the original DataFrame index for merging\n",
    "days_of_week.index = df.index\n",
    "# Join the dataframe with the days of week DataFrame\n",
    "df = pd.concat([df, days_of_week], axis=1)\n",
    "df = df[df.weekday_6 == 0]\n",
    "df.drop(df.columns[[2,3,4,5,6]], axis=1, inplace=True)  # df.columns is zero-based pd.Index $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-02</th>\n",
       "      <td>1830</td>\n",
       "      <td>1.10014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.09859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03</th>\n",
       "      <td>1830</td>\n",
       "      <td>1.09362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.09390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04</th>\n",
       "      <td>1830</td>\n",
       "      <td>1.09593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-17</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.06647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-18</th>\n",
       "      <td>1830</td>\n",
       "      <td>1.06655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-18</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.06624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-19</th>\n",
       "      <td>1830</td>\n",
       "      <td>1.06504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-19</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.06468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            time    close\n",
       "date                     \n",
       "2019-12-02  1830  1.10014\n",
       "2019-12-02  2330  1.09859\n",
       "2019-12-03  1830  1.09362\n",
       "2019-12-03  2330  1.09390\n",
       "2019-12-04  1830  1.09593\n",
       "...          ...      ...\n",
       "2020-06-17  2330  1.06647\n",
       "2020-06-18  1830  1.06655\n",
       "2020-06-18  2330  1.06624\n",
       "2020-06-19  1830  1.06504\n",
       "2020-06-19  2330  1.06468\n",
       "\n",
       "[289 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['eurchf'] = df['close'].pct_change(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>close</th>\n",
       "      <th>eurchf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-02</th>\n",
       "      <td>1830</td>\n",
       "      <td>1.10014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.09859</td>\n",
       "      <td>-0.001409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03</th>\n",
       "      <td>1830</td>\n",
       "      <td>1.09362</td>\n",
       "      <td>-0.004524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.09390</td>\n",
       "      <td>0.000256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04</th>\n",
       "      <td>1830</td>\n",
       "      <td>1.09593</td>\n",
       "      <td>0.001856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-17</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.06647</td>\n",
       "      <td>-0.001246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-18</th>\n",
       "      <td>1830</td>\n",
       "      <td>1.06655</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-18</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.06624</td>\n",
       "      <td>-0.000291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-19</th>\n",
       "      <td>1830</td>\n",
       "      <td>1.06504</td>\n",
       "      <td>-0.001125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-19</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.06468</td>\n",
       "      <td>-0.000338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            time    close    eurchf\n",
       "date                               \n",
       "2019-12-02  1830  1.10014       NaN\n",
       "2019-12-02  2330  1.09859 -0.001409\n",
       "2019-12-03  1830  1.09362 -0.004524\n",
       "2019-12-03  2330  1.09390  0.000256\n",
       "2019-12-04  1830  1.09593  0.001856\n",
       "...          ...      ...       ...\n",
       "2020-06-17  2330  1.06647 -0.001246\n",
       "2020-06-18  1830  1.06655  0.000075\n",
       "2020-06-18  2330  1.06624 -0.000291\n",
       "2020-06-19  1830  1.06504 -0.001125\n",
       "2020-06-19  2330  1.06468 -0.000338\n",
       "\n",
       "[289 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.time == 2330]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>close</th>\n",
       "      <th>eurchf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-02</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.09859</td>\n",
       "      <td>-0.001409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.09390</td>\n",
       "      <td>0.000256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.09565</td>\n",
       "      <td>-0.000255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.09587</td>\n",
       "      <td>-0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.09480</td>\n",
       "      <td>-0.000393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-15</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.07397</td>\n",
       "      <td>0.002942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-16</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.07119</td>\n",
       "      <td>0.001374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-17</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.06647</td>\n",
       "      <td>-0.001246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-18</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.06624</td>\n",
       "      <td>-0.000291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-19</th>\n",
       "      <td>2330</td>\n",
       "      <td>1.06468</td>\n",
       "      <td>-0.000338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            time    close    eurchf\n",
       "date                               \n",
       "2019-12-02  2330  1.09859 -0.001409\n",
       "2019-12-03  2330  1.09390  0.000256\n",
       "2019-12-04  2330  1.09565 -0.000255\n",
       "2019-12-05  2330  1.09587 -0.000839\n",
       "2019-12-06  2330  1.09480 -0.000393\n",
       "...          ...      ...       ...\n",
       "2020-06-15  2330  1.07397  0.002942\n",
       "2020-06-16  2330  1.07119  0.001374\n",
       "2020-06-17  2330  1.06647 -0.001246\n",
       "2020-06-18  2330  1.06624 -0.000291\n",
       "2020-06-19  2330  1.06468 -0.000338\n",
       "\n",
       "[145 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns[1], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "#df.drop(df.columns[[0,1]], axis=1, inplace=True)  # df.columns is zero-based pd.Index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>eurchf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-02</th>\n",
       "      <td>2330</td>\n",
       "      <td>-0.001409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03</th>\n",
       "      <td>2330</td>\n",
       "      <td>0.000256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04</th>\n",
       "      <td>2330</td>\n",
       "      <td>-0.000255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05</th>\n",
       "      <td>2330</td>\n",
       "      <td>-0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06</th>\n",
       "      <td>2330</td>\n",
       "      <td>-0.000393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-15</th>\n",
       "      <td>2330</td>\n",
       "      <td>0.002942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-16</th>\n",
       "      <td>2330</td>\n",
       "      <td>0.001374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-17</th>\n",
       "      <td>2330</td>\n",
       "      <td>-0.001246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-18</th>\n",
       "      <td>2330</td>\n",
       "      <td>-0.000291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-19</th>\n",
       "      <td>2330</td>\n",
       "      <td>-0.000338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            time    eurchf\n",
       "date                      \n",
       "2019-12-02  2330 -0.001409\n",
       "2019-12-03  2330  0.000256\n",
       "2019-12-04  2330 -0.000255\n",
       "2019-12-05  2330 -0.000839\n",
       "2019-12-06  2330 -0.000393\n",
       "...          ...       ...\n",
       "2020-06-15  2330  0.002942\n",
       "2020-06-16  2330  0.001374\n",
       "2020-06-17  2330 -0.001246\n",
       "2020-06-18  2330 -0.000291\n",
       "2020-06-19  2330 -0.000338\n",
       "\n",
       "[145 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final_df = pd.concat([final_df, df], axis=1)\n",
    "final_df =df\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USD/CHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='CHFJPY.csv'\n",
    "df = pd.read_csv(file, na_values='n/a', parse_dates=[0], index_col = [0], usecols=[2,3,4], names=[\"date\", \"time\", \"close\"], header=0)\n",
    "# Mask for specific TIME\n",
    "time_1830 = df.time == 1830\n",
    "time_2330 = df.time == 2330\n",
    "\n",
    "# Filter using the mask\n",
    "df1=df.loc[time_1830]\n",
    "df2=df.loc[time_2330]\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = df.sort_values(['date','time'])\n",
    "\n",
    "# import datetime class from datetime module\n",
    "from datetime import datetime\n",
    "# import calendar module\n",
    "import calendar\n",
    "\n",
    "# Use pandas' get_dummies function to get dummies for day of the week\n",
    "days_of_week = pd.get_dummies(df.index.dayofweek,\n",
    "                              prefix='weekday',\n",
    "                              drop_first=True)\n",
    "\n",
    "# Set the index as the original DataFrame index for merging\n",
    "days_of_week.index = df.index\n",
    "# Join the dataframe with the days of week DataFrame\n",
    "df = pd.concat([df, days_of_week], axis=1)\n",
    "df = df[df.weekday_6 == 0]\n",
    "df.drop(df.columns[[2,3,4,5,6]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "df['usdjpy'] = df['close'].pct_change(1)\n",
    "df = df[df.time == 2330]\n",
    "df.drop(df.columns[[0,1]], axis=1, inplace=True)  # df.columns is zero-based pd.Index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([final_df, df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DJ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='DJ.csv'\n",
    "df = pd.read_csv(file, na_values='n/a', parse_dates=[0], index_col = [0], usecols=[2,3,4], names=[\"date\", \"time\", \"close\"], header=0)\n",
    "# Mask for specific TIME\n",
    "time_1830 = df.time == 1830\n",
    "time_2330 = df.time == 2330\n",
    "\n",
    "# Filter using the mask\n",
    "df1=df.loc[time_1830]\n",
    "df2=df.loc[time_2330]\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = df.sort_values(['date','time'])\n",
    "\n",
    "\n",
    "df['dj'] = df['close'].pct_change(1)\n",
    "df = df[df.time == 2330]\n",
    "df.drop(df.columns[[0,1]], axis=1, inplace=True)  # df.columns is zero-based pd.Index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([final_df, df], axis=1)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOLLARINDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='DOLLARINDEX.csv'\n",
    "df = pd.read_csv(file, na_values='n/a', parse_dates=[0], index_col = [0], usecols=[2,3,4], names=[\"date\", \"time\", \"close\"], header=0)\n",
    "# Mask for specific TIME\n",
    "time_1830 = df.time == 1830\n",
    "time_2330 = df.time == 2200\n",
    "\n",
    "# Filter using the mask\n",
    "df1=df.loc[time_1830]\n",
    "df2=df.loc[time_2330]\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = df.sort_values(['date','time'])\n",
    "\n",
    "\n",
    "df['dollind'] = df['close'].pct_change(1)\n",
    "df = df[df.time == 2200]\n",
    "df.drop(df.columns[[0,1]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "final_df = pd.concat([final_df, df], axis=1)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EURCHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambiare nome file\n",
    "file='EURCHF.csv'\n",
    "df = pd.read_csv(file, na_values='n/a', parse_dates=[0], index_col = [0], usecols=[2,3,4], names=[\"date\", \"time\", \"close\"], header=0)\n",
    "# Mask for specific TIME\n",
    "time_1830 = df.time == 1830\n",
    "time_2330 = df.time == 2330\n",
    "\n",
    "# Filter using the mask\n",
    "df1=df.loc[time_1830]\n",
    "df2=df.loc[time_2330]\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = df.sort_values(['date','time'])\n",
    "\n",
    "\n",
    "# se weekday ok\n",
    "#################################################\n",
    "# import datetime class from datetime module\n",
    "from datetime import datetime\n",
    "# import calendar module\n",
    "import calendar\n",
    "\n",
    "# Use pandas' get_dummies function to get dummies for day of the week\n",
    "days_of_week = pd.get_dummies(df.index.dayofweek,\n",
    "                              prefix='weekday',\n",
    "                              drop_first=True)\n",
    "\n",
    "# Set the index as the original DataFrame index for merging\n",
    "days_of_week.index = df.index\n",
    "# Join the dataframe with the days of week DataFrame\n",
    "df = pd.concat([df, days_of_week], axis=1)\n",
    "df = df[df.weekday_6 == 0]\n",
    "df.drop(df.columns[[2,3,4,5,6]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "##################################################################\n",
    "\n",
    "df['eurchf'] = df['close'].pct_change(1) # crea colonna con nome feature e calcola var percent\n",
    "df = df[df.time == 2330]                 # seleziona solo righe chiusura\n",
    "df.drop(df.columns[[0,1]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "final_df = pd.concat([final_df, df], axis=1)  # aggiungi colonna a final_df\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EURGBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambiare nome file\n",
    "file='EURGBP.csv'\n",
    "df = pd.read_csv(file, na_values='n/a', parse_dates=[0], index_col = [0], usecols=[2,3,4], names=[\"date\", \"time\", \"close\"], header=0)\n",
    "# Mask for specific TIME\n",
    "time_1830 = df.time == 1830\n",
    "time_2330 = df.time == 2330\n",
    "\n",
    "# Filter using the mask\n",
    "df1=df.loc[time_1830]\n",
    "df2=df.loc[time_2330]\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = df.sort_values(['date','time'])\n",
    "\n",
    "\n",
    "# se weekday ok\n",
    "#################################################\n",
    "# import datetime class from datetime module\n",
    "from datetime import datetime\n",
    "# import calendar module\n",
    "import calendar\n",
    "\n",
    "# Use pandas' get_dummies function to get dummies for day of the week\n",
    "days_of_week = pd.get_dummies(df.index.dayofweek,\n",
    "                              prefix='weekday',\n",
    "                              drop_first=True)\n",
    "\n",
    "# Set the index as the original DataFrame index for merging\n",
    "days_of_week.index = df.index\n",
    "# Join the dataframe with the days of week DataFrame\n",
    "df = pd.concat([df, days_of_week], axis=1)\n",
    "df = df[df.weekday_6 == 0]\n",
    "df.drop(df.columns[[2,3,4,5,6]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "##################################################################\n",
    "\n",
    "df['eurgbp'] = df['close'].pct_change(1) # crea colonna con nome feature e calcola var percent\n",
    "df = df[df.time == 2330]                 # seleziona solo righe chiusura\n",
    "df.drop(df.columns[[0,1]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "final_df = pd.concat([final_df, df], axis=1)  # aggiungi colonna a final_df\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EURUSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambiare nome file\n",
    "file='EURUSD.csv'\n",
    "df = pd.read_csv(file, na_values='n/a', parse_dates=[0], index_col = [0], usecols=[2,3,4], names=[\"date\", \"time\", \"close\"], header=0)\n",
    "# Mask for specific TIME\n",
    "time_1830 = df.time == 1830\n",
    "time_2330 = df.time == 2330\n",
    "\n",
    "# Filter using the mask\n",
    "df1=df.loc[time_1830]\n",
    "df2=df.loc[time_2330]\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = df.sort_values(['date','time'])\n",
    "\n",
    "\n",
    "# se weekday ok\n",
    "#################################################\n",
    "# import datetime class from datetime module\n",
    "from datetime import datetime\n",
    "# import calendar module\n",
    "import calendar\n",
    "\n",
    "# Use pandas' get_dummies function to get dummies for day of the week\n",
    "days_of_week = pd.get_dummies(df.index.dayofweek,\n",
    "                              prefix='weekday',\n",
    "                              drop_first=True)\n",
    "\n",
    "# Set the index as the original DataFrame index for merging\n",
    "days_of_week.index = df.index\n",
    "# Join the dataframe with the days of week DataFrame\n",
    "df = pd.concat([df, days_of_week], axis=1)\n",
    "df = df[df.weekday_6 == 0]\n",
    "df.drop(df.columns[[2,3,4,5,6]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "##################################################################\n",
    "\n",
    "df['eurusd'] = df['close'].pct_change(1) # crea colonna con nome feature e calcola var percent\n",
    "df = df[df.time == 2330]                 # seleziona solo righe chiusura\n",
    "df.drop(df.columns[[0,1]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "final_df = pd.concat([final_df, df], axis=1)  # aggiungi colonna a final_df\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUTSEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambiare nome file\n",
    "file='FUTSEE.csv'\n",
    "df = pd.read_csv(file, na_values='n/a', parse_dates=[0], index_col = [0], usecols=[2,3,4], names=[\"date\", \"time\", \"close\"], header=0)\n",
    "# Mask for specific TIME\n",
    "time_1830 = df.time == 1830\n",
    "time_2330 = df.time == 1900\n",
    "\n",
    "# Filter using the mask\n",
    "df1=df.loc[time_1830]\n",
    "df2=df.loc[time_2330]\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = df.sort_values(['date','time'])\n",
    "\n",
    "\n",
    "# se weekday ok\n",
    "\n",
    "\n",
    "df['futsee'] = df['close'].pct_change(1) # crea colonna con nome feature e calcola var percent\n",
    "df = df[df.time == 1900]                 # seleziona solo righe chiusura\n",
    "df.drop(df.columns[[0,1]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "final_df = pd.concat([final_df, df], axis=1)  # aggiungi colonna a final_df\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBPCHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambiare nome file\n",
    "file='GBPCHF.csv'\n",
    "df = pd.read_csv(file, na_values='n/a', parse_dates=[0], index_col = [0], usecols=[2,3,4], names=[\"date\", \"time\", \"close\"], header=0)\n",
    "# Mask for specific TIME\n",
    "time_1830 = df.time == 1830\n",
    "time_2330 = df.time == 2330\n",
    "\n",
    "# Filter using the mask\n",
    "df1=df.loc[time_1830]\n",
    "df2=df.loc[time_2330]\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = df.sort_values(['date','time'])\n",
    "\n",
    "\n",
    "# se weekday ok\n",
    "#################################################\n",
    "# import datetime class from datetime module\n",
    "from datetime import datetime\n",
    "# import calendar module\n",
    "import calendar\n",
    "\n",
    "# Use pandas' get_dummies function to get dummies for day of the week\n",
    "days_of_week = pd.get_dummies(df.index.dayofweek,\n",
    "                              prefix='weekday',\n",
    "                              drop_first=True)\n",
    "\n",
    "# Set the index as the original DataFrame index for merging\n",
    "days_of_week.index = df.index\n",
    "# Join the dataframe with the days of week DataFrame\n",
    "df = pd.concat([df, days_of_week], axis=1)\n",
    "df = df[df.weekday_6 == 0]\n",
    "df.drop(df.columns[[2,3,4,5,6]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "##################################################################\n",
    "\n",
    "df['gbpchf'] = df['close'].pct_change(1) # crea colonna con nome feature e calcola var percent\n",
    "df = df[df.time == 2330]                 # seleziona solo righe chiusura\n",
    "df.drop(df.columns[[0,1]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "final_df = pd.concat([final_df, df], axis=1)  # aggiungi colonna a final_df\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBPUSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambiare nome file\n",
    "file='GBPUSD.csv'\n",
    "df = pd.read_csv(file, na_values='n/a', parse_dates=[0], index_col = [0], usecols=[2,3,4], names=[\"date\", \"time\", \"close\"], header=0)\n",
    "# Mask for specific TIME\n",
    "time_1830 = df.time == 1830\n",
    "time_2330 = df.time == 2330\n",
    "\n",
    "# Filter using the mask\n",
    "df1=df.loc[time_1830]\n",
    "df2=df.loc[time_2330]\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = df.sort_values(['date','time'])\n",
    "\n",
    "\n",
    "# se weekday ok\n",
    "#################################################\n",
    "# import datetime class from datetime module\n",
    "from datetime import datetime\n",
    "# import calendar module\n",
    "import calendar\n",
    "\n",
    "# Use pandas' get_dummies function to get dummies for day of the week\n",
    "days_of_week = pd.get_dummies(df.index.dayofweek,\n",
    "                              prefix='weekday',\n",
    "                              drop_first=True)\n",
    "\n",
    "# Set the index as the original DataFrame index for merging\n",
    "days_of_week.index = df.index\n",
    "# Join the dataframe with the days of week DataFrame\n",
    "df = pd.concat([df, days_of_week], axis=1)\n",
    "df = df[df.weekday_6 == 0]\n",
    "df.drop(df.columns[[2,3,4,5,6]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "##################################################################\n",
    "\n",
    "df['gbpusd'] = df['close'].pct_change(1) # crea colonna con nome feature e calcola var percent\n",
    "df = df[df.time == 2330]                 # seleziona solo righe chiusura\n",
    "df.drop(df.columns[[0,1]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "final_df = pd.concat([final_df, df], axis=1)  # aggiungi colonna a final_df\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambiare nome file\n",
    "file='LIGHT.csv'\n",
    "df = pd.read_csv(file, na_values='n/a', parse_dates=[0], index_col = [0], usecols=[2,3,4], names=[\"date\", \"time\", \"close\"], header=0)\n",
    "# Mask for specific TIME\n",
    "time_1830 = df.time == 1830\n",
    "time_2330 = df.time == 2330\n",
    "\n",
    "# Filter using the mask\n",
    "df1=df.loc[time_1830]\n",
    "df2=df.loc[time_2330]\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = df.sort_values(['date','time'])\n",
    "\n",
    "\n",
    "# se weekday ok\n",
    "#################################################\n",
    "# import datetime class from datetime module\n",
    "from datetime import datetime\n",
    "# import calendar module\n",
    "import calendar\n",
    "\n",
    "# Use pandas' get_dummies function to get dummies for day of the week\n",
    "days_of_week = pd.get_dummies(df.index.dayofweek,\n",
    "                              prefix='weekday',\n",
    "                              drop_first=True)\n",
    "\n",
    "# Set the index as the original DataFrame index for merging\n",
    "days_of_week.index = df.index\n",
    "# Join the dataframe with the days of week DataFrame\n",
    "df = pd.concat([df, days_of_week], axis=1)\n",
    "df = df[df.weekday_6 == 0]\n",
    "df.drop(df.columns[[2,3,4,5,6]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "##################################################################\n",
    "\n",
    "df['light'] = df['close'].pct_change(1) # crea colonna con nome feature e calcola var percent\n",
    "df = df[df.time == 2330]                 # seleziona solo righe chiusura\n",
    "df.drop(df.columns[[0,1]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "final_df = pd.concat([final_df, df], axis=1)  # aggiungi colonna a final_df\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MINIDJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambiare nome file\n",
    "file='MINIDJ.csv'\n",
    "df = pd.read_csv(file, na_values='n/a', parse_dates=[0], index_col = [0], usecols=[2,3,4], names=[\"date\", \"time\", \"close\"], header=0)\n",
    "# Mask for specific TIME\n",
    "time_1830 = df.time == 1830\n",
    "time_2330 = df.time == 2330\n",
    "\n",
    "# Filter using the mask\n",
    "df1=df.loc[time_1830]\n",
    "df2=df.loc[time_2330]\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = df.sort_values(['date','time'])\n",
    "\n",
    "\n",
    "# se weekday ok\n",
    "\n",
    "\n",
    "df['minidj'] = df['close'].pct_change(1) # crea colonna con nome feature e calcola var percent\n",
    "df = df[df.time == 2330]                 # seleziona solo righe chiusura\n",
    "df.drop(df.columns[[0,1]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "final_df = pd.concat([final_df, df], axis=1)  # aggiungi colonna a final_df\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MINISP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambiare nome file\n",
    "file='MINISP.csv'\n",
    "df = pd.read_csv(file, na_values='n/a', parse_dates=[0], index_col = [0], usecols=[2,3,4], names=[\"date\", \"time\", \"close\"], header=0)\n",
    "# Mask for specific TIME\n",
    "time_1830 = df.time == 1830\n",
    "time_2330 = df.time == 2330\n",
    "\n",
    "# Filter using the mask\n",
    "df1=df.loc[time_1830]\n",
    "df2=df.loc[time_2330]\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = df.sort_values(['date','time'])\n",
    "\n",
    "# import datetime class from datetime module\n",
    "from datetime import datetime\n",
    "# import calendar module\n",
    "import calendar\n",
    "\n",
    "# Use pandas' get_dummies function to get dummies for day of the week\n",
    "days_of_week = pd.get_dummies(df.index.dayofweek,\n",
    "                              prefix='weekday',\n",
    "                              drop_first=True)\n",
    "\n",
    "# Set the index as the original DataFrame index for merging\n",
    "days_of_week.index = df.index\n",
    "# Join the dataframe with the days of week DataFrame\n",
    "df = pd.concat([df, days_of_week], axis=1)\n",
    "#df = df[df.weekday_6 == 0]\n",
    "df.drop(df.columns[[2,3,4,5]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "df['minisp'] = df['close'].pct_change(1)\n",
    "df = df[df.time == 2330]\n",
    "df.drop(df.columns[[0,1]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "final_df = pd.concat([final_df, df], axis=1)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambiare nome file\n",
    "file='SP.csv'\n",
    "df = pd.read_csv(file, na_values='n/a', parse_dates=[0], index_col = [0], usecols=[2,3,4], names=[\"date\", \"time\", \"close\"], header=0)\n",
    "# Mask for specific TIME\n",
    "time_1830 = df.time == 1830\n",
    "time_2330 = df.time == 2330\n",
    "\n",
    "# Filter using the mask\n",
    "df1=df.loc[time_1830]\n",
    "df2=df.loc[time_2330]\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = df.sort_values(['date','time'])\n",
    "\n",
    "\n",
    "# se weekday ok\n",
    "\n",
    "\n",
    "df['sp'] = df['close'].pct_change(1) # crea colonna con nome feature e calcola var percent\n",
    "df = df[df.time == 2330]                 # seleziona solo righe chiusura\n",
    "df.drop(df.columns[[0,1]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "final_df = pd.concat([final_df, df], axis=1)  # aggiungi colonna a final_df\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USDCHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambiare nome file\n",
    "file='USDCHF.csv'\n",
    "df = pd.read_csv(file, na_values='n/a', parse_dates=[0], index_col = [0], usecols=[2,3,4], names=[\"date\", \"time\", \"close\"], header=0)\n",
    "# Mask for specific TIME\n",
    "time_1830 = df.time == 1830\n",
    "time_2330 = df.time == 2330\n",
    "\n",
    "# Filter using the mask\n",
    "df1=df.loc[time_1830]\n",
    "df2=df.loc[time_2330]\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = df.sort_values(['date','time'])\n",
    "\n",
    "\n",
    "# se weekday ok\n",
    "#################################################\n",
    "# import datetime class from datetime module\n",
    "from datetime import datetime\n",
    "# import calendar module\n",
    "import calendar\n",
    "\n",
    "# Use pandas' get_dummies function to get dummies for day of the week\n",
    "days_of_week = pd.get_dummies(df.index.dayofweek,\n",
    "                              prefix='weekday',\n",
    "                              drop_first=True)\n",
    "\n",
    "# Set the index as the original DataFrame index for merging\n",
    "days_of_week.index = df.index\n",
    "# Join the dataframe with the days of week DataFrame\n",
    "df = pd.concat([df, days_of_week], axis=1)\n",
    "df = df[df.weekday_6 == 0]\n",
    "df.drop(df.columns[[2,3,4,5,6]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "##################################################################\n",
    "\n",
    "df['usdchf'] = df['close'].pct_change(1) # crea colonna con nome feature e calcola var percent\n",
    "df = df[df.time == 2330]                 # seleziona solo righe chiusura\n",
    "df.drop(df.columns[[0,1]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "final_df = pd.concat([final_df, df], axis=1)  # aggiungi colonna a final_df\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USDJPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambiare nome file\n",
    "file='USDJPY.csv'\n",
    "df = pd.read_csv(file, na_values='n/a', parse_dates=[0], index_col = [0], usecols=[2,3,4], names=[\"date\", \"time\", \"close\"], header=0)\n",
    "# Mask for specific TIME\n",
    "time_1830 = df.time == 1830\n",
    "time_2330 = df.time == 2330\n",
    "\n",
    "# Filter using the mask\n",
    "df1=df.loc[time_1830]\n",
    "df2=df.loc[time_2330]\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = df.sort_values(['date','time'])\n",
    "\n",
    "\n",
    "# se weekday ok\n",
    "#################################################\n",
    "# import datetime class from datetime module\n",
    "from datetime import datetime\n",
    "# import calendar module\n",
    "import calendar\n",
    "\n",
    "# Use pandas' get_dummies function to get dummies for day of the week\n",
    "days_of_week = pd.get_dummies(df.index.dayofweek,\n",
    "                              prefix='weekday',\n",
    "                              drop_first=True)\n",
    "\n",
    "# Set the index as the original DataFrame index for merging\n",
    "days_of_week.index = df.index\n",
    "# Join the dataframe with the days of week DataFrame\n",
    "df = pd.concat([df, days_of_week], axis=1)\n",
    "df = df[df.weekday_6 == 0]\n",
    "df.drop(df.columns[[2,3,4,5,6]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "##################################################################\n",
    "\n",
    "df['usdjpy'] = df['close'].pct_change(1) # crea colonna con nome feature e calcola var percent\n",
    "df = df[df.time == 2330]                 # seleziona solo righe chiusura\n",
    "df.drop(df.columns[[0,1]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "final_df = pd.concat([final_df, df], axis=1)  # aggiungi colonna a final_df\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambiare nome file\n",
    "file='XAG.csv'\n",
    "df = pd.read_csv(file, na_values='n/a', parse_dates=[0], index_col = [0], usecols=[2,3,4], names=[\"date\", \"time\", \"close\"], header=0)\n",
    "# Mask for specific TIME\n",
    "time_1830 = df.time == 1830\n",
    "time_2330 = df.time == 2330\n",
    "\n",
    "# Filter using the mask\n",
    "df1=df.loc[time_1830]\n",
    "df2=df.loc[time_2330]\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = df.sort_values(['date','time'])\n",
    "\n",
    "\n",
    "# se weekday ok\n",
    "\n",
    "\n",
    "df['xag'] = df['close'].pct_change(1) # crea colonna con nome feature e calcola var percent\n",
    "df = df[df.time == 2330]                 # seleziona solo righe chiusura\n",
    "df.drop(df.columns[[0,1]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "final_df = pd.concat([final_df, df], axis=1)  # aggiungi colonna a final_df\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XAU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='XAU3.csv'\n",
    "df = pd.read_csv(file,index_col = [0],parse_dates=[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>eurchf</th>\n",
       "      <th>xau</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-02</th>\n",
       "      <td>2330</td>\n",
       "      <td>-0.001409</td>\n",
       "      <td>-0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03</th>\n",
       "      <td>2330</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.001433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04</th>\n",
       "      <td>2330</td>\n",
       "      <td>-0.000255</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05</th>\n",
       "      <td>2330</td>\n",
       "      <td>-0.000839</td>\n",
       "      <td>-0.000759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06</th>\n",
       "      <td>2330</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-15</th>\n",
       "      <td>2330</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.002686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-16</th>\n",
       "      <td>2330</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>-0.000726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-17</th>\n",
       "      <td>2330</td>\n",
       "      <td>-0.001246</td>\n",
       "      <td>0.001719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-18</th>\n",
       "      <td>2330</td>\n",
       "      <td>-0.000291</td>\n",
       "      <td>0.000349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-19</th>\n",
       "      <td>2330</td>\n",
       "      <td>-0.000338</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            time    eurchf       xau\n",
       "date                                \n",
       "2019-12-02  2330 -0.001409 -0.001000\n",
       "2019-12-03  2330  0.000256  0.001433\n",
       "2019-12-04  2330 -0.000255  0.000100\n",
       "2019-12-05  2330 -0.000839 -0.000759\n",
       "2019-12-06  2330 -0.000393       NaN\n",
       "...          ...       ...       ...\n",
       "2020-06-15  2330  0.002942  0.002686\n",
       "2020-06-16  2330  0.001374 -0.000726\n",
       "2020-06-17  2330 -0.001246  0.001719\n",
       "2020-06-18  2330 -0.000291  0.000349\n",
       "2020-06-19  2330 -0.000338  0.000041\n",
       "\n",
       "[145 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file='XAU4.csv'\n",
    "df = pd.read_csv(file,index_col = [0],parse_dates=[0])\n",
    "final_df = pd.concat([final_df, df], axis=1)  # aggiungi colonna a final_df\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            time    eurchf       xau\n",
      "date                                \n",
      "2019-12-02  2330 -0.001409 -0.001000\n",
      "2019-12-03  2330  0.000256  0.001433\n",
      "2019-12-04  2330 -0.000255  0.000100\n",
      "2019-12-05  2330 -0.000839 -0.000759\n",
      "2019-12-06  2330 -0.000393       NaN\n",
      "2019-12-09  2330 -0.001744 -0.000629\n",
      "2019-12-10  2330 -0.001445 -0.000710\n",
      "2019-12-11  2330  0.000064  0.000283\n",
      "2019-12-12  2330 -0.000665  0.001903\n",
      "2019-12-13  2330 -0.001433       NaN\n",
      "2019-12-16  2330 -0.000301  0.000773\n",
      "2019-12-17  2330 -0.000941  0.000528\n",
      "2019-12-18  2330 -0.000908  0.001604\n",
      "2019-12-19  2330  0.000801  0.000149\n",
      "2019-12-20  2330 -0.000340       NaN\n",
      "2019-12-23  2330  0.000469  0.001804\n",
      "2019-12-24  2330 -0.000727       NaN\n",
      "2019-12-25  2330 -0.002185  0.002718\n",
      "2019-12-26  2330  0.000404  0.001271\n",
      "2019-12-27  2330 -0.000009       NaN\n",
      "2019-12-30  2330  0.000240  0.004961\n",
      "2019-12-31  2330 -0.000101       NaN\n",
      "2020-01-01  2330  0.000304  0.000136\n",
      "2020-01-02  2330  0.000830  0.006701\n",
      "2020-01-03  2330  0.000387       NaN\n",
      "2020-01-06  2330 -0.001096 -0.003765\n",
      "2020-01-07  2330 -0.000831  0.003563\n",
      "2020-01-08  2330  0.003088  0.000186\n",
      "2020-01-09  2330  0.000843 -0.003704\n",
      "2020-01-10  2330  0.000240       NaN\n",
      "2020-01-13  2330  0.000991 -0.006055\n",
      "2020-01-14  2330 -0.000566  0.002385\n",
      "2020-01-15  2330 -0.000493  0.000011\n",
      "2020-01-16  2330  0.000792  0.002364\n",
      "2020-01-17  2330 -0.001386       NaN\n",
      "2020-01-20  2330  0.000456  0.004210\n",
      "2020-01-21  2330  0.000102 -0.003340\n",
      "2020-01-22  2330 -0.000651 -0.001813\n",
      "2020-01-23  2330  0.000607 -0.000463\n",
      "2020-01-24  2330  0.000495       NaN\n",
      "2020-01-27  2330 -0.000056 -0.000559\n",
      "2020-01-28  2330  0.001055 -0.002121\n",
      "2020-01-29  2330 -0.000261  0.002247\n",
      "2020-01-30  2330  0.000243 -0.001523\n",
      "2020-01-31  2330 -0.000047       NaN\n",
      "2020-02-03  2330  0.001152       NaN\n",
      "2020-02-04  2330  0.000336  0.000862\n",
      "2020-02-05  2330  0.000262 -0.000664\n",
      "2020-02-06  2330 -0.000430  0.001531\n",
      "2020-02-07  2330  0.000178  0.000892\n",
      "2020-02-10  2330 -0.001742 -0.000556\n",
      "2020-02-11  2330 -0.001949  0.000595\n",
      "2020-02-12  2330 -0.000404  0.000300\n",
      "2020-02-13  2330  0.000858 -0.000798\n",
      "2020-02-14  2330  0.000103       NaN\n",
      "2020-02-17  2330 -0.000752       NaN\n",
      "2020-02-18  2330 -0.000876       NaN\n",
      "2020-02-19  2330  0.001555       NaN\n",
      "2020-02-20  2330 -0.000556       NaN\n",
      "2020-02-21  2330 -0.000659       NaN\n",
      "2020-02-24  2330  0.001547       NaN\n",
      "2020-02-25  2330  0.002322       NaN\n",
      "2020-02-26  2330  0.001196       NaN\n",
      "2020-02-27  2330  0.000836       NaN\n",
      "2020-02-28  2330  0.004958       NaN\n",
      "2020-03-02  2330  0.004569       NaN\n",
      "2020-03-03  2330  0.002296       NaN\n",
      "2020-03-04  2330  0.001608       NaN\n",
      "2020-03-05  2330 -0.001598       NaN\n",
      "2020-03-06  2330  0.002618       NaN\n",
      "2020-03-09  2330  0.001079       NaN\n",
      "2020-03-10  2330  0.000746       NaN\n",
      "2020-03-11  2330 -0.000501       NaN\n",
      "2020-03-12  2330  0.001526       NaN\n",
      "2020-03-13  2330  0.000975       NaN\n",
      "2020-03-16  2330  0.002665       NaN\n",
      "2020-03-17  2330  0.000559 -0.029710\n",
      "2020-03-18  2330  0.001233 -0.005422\n",
      "2020-03-19  2330  0.000446 -0.005350\n",
      "2020-03-20  2330  0.000218 -0.002770\n",
      "2020-03-23  2330 -0.001712  0.006246\n",
      "2020-03-24  2330 -0.000585  0.015283\n",
      "2020-03-25  2330  0.003438 -0.001025\n",
      "2020-03-26  2330 -0.001485 -0.003302\n",
      "2020-03-27  2330  0.001948 -0.000450\n",
      "2020-03-30  2330  0.000935  0.001438\n",
      "2020-03-31  2330  0.000490 -0.021914\n",
      "2020-04-01  2330  0.000615  0.001142\n",
      "2020-04-02  2330  0.000881  0.003623\n",
      "2020-04-03  2330 -0.000227  0.003492\n",
      "2020-04-06  2330 -0.000028  0.010524\n",
      "2020-04-07  2330 -0.000596 -0.003932\n",
      "2020-04-08  2330  0.000000 -0.003249\n",
      "2020-04-09  2330  0.000000  0.002140\n",
      "2020-04-10  2330 -0.000199       NaN\n",
      "2020-04-13  2330  0.000265  0.004158\n",
      "2020-04-14  2330  0.000531 -0.005777\n",
      "2020-04-15  2330 -0.000057  0.001008\n",
      "2020-04-16  2330 -0.000209 -0.004811\n",
      "2020-04-17  2330 -0.000010 -0.005107\n",
      "2020-04-20  2330 -0.000371  0.001258\n",
      "2020-04-21  2330  0.000960  0.001348\n",
      "2020-04-22  2330  0.000095  0.003584\n",
      "2020-04-23  2330 -0.000637 -0.001090\n",
      "2020-04-24  2330  0.000494  0.005735\n",
      "2020-04-27  2330 -0.000804  0.002010\n",
      "2020-04-28  2330 -0.000890  0.002973\n",
      "2020-04-29  2330  0.002668  0.006393\n",
      "2020-04-30  2330 -0.000095 -0.010886\n",
      "2020-05-01  2330 -0.000918  0.003221\n",
      "2020-05-04  2330 -0.000294       NaN\n",
      "2020-05-05  2330  0.000180       NaN\n",
      "2020-05-06  2330 -0.000123       NaN\n",
      "2020-05-07  2330  0.000218  0.008956\n",
      "2020-05-08  2330 -0.000494 -0.004375\n",
      "2020-05-11  2330 -0.000133       NaN\n",
      "2020-05-12  2330  0.000466 -0.004975\n",
      "2020-05-13  2330 -0.000485 -0.000532\n",
      "2020-05-14  2330  0.000704 -0.000334\n",
      "2020-05-15  2330 -0.000722       NaN\n",
      "2020-05-18  2330  0.007115  0.000775\n",
      "2020-05-19  2330 -0.000969  0.003096\n",
      "2020-05-20  2330 -0.000830 -0.001920\n",
      "2020-05-21  2330  0.000753  0.002382\n",
      "2020-05-22  2330  0.000009  0.002062\n",
      "2020-05-25  2330  0.000208       NaN\n",
      "2020-05-26  2330 -0.001413 -0.000444\n",
      "2020-05-27  2330  0.001419  0.006568\n",
      "2020-05-28  2330  0.000872 -0.002139\n",
      "2020-05-29  2330 -0.002104 -0.000892\n",
      "2020-06-01  2330  0.000776  0.000334\n",
      "2020-06-02  2330  0.000596 -0.003782\n",
      "2020-06-03  2330 -0.000472  0.000628\n",
      "2020-06-04  2330  0.000526  0.001210\n",
      "2020-06-05  2330 -0.002718  0.004205\n",
      "2020-06-08  2330 -0.000407  0.004015\n",
      "2020-06-09  2330  0.000102 -0.001155\n",
      "2020-06-10  2330 -0.000457  0.010497\n",
      "2020-06-11  2330 -0.001705 -0.009103\n",
      "2020-06-12  2330  0.001280 -0.000607\n",
      "2020-06-15  2330  0.002942  0.002686\n",
      "2020-06-16  2330  0.001374 -0.000726\n",
      "2020-06-17  2330 -0.001246  0.001719\n",
      "2020-06-18  2330 -0.000291  0.000349\n",
      "2020-06-19  2330 -0.000338  0.000041\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambiare nome file\n",
    "file='SMI.csv'\n",
    "df = pd.read_csv(file, na_values='n/a', parse_dates=[0], index_col = [0], usecols=[0,4], names=[\"date\", \"close\"], header=0)\n",
    "\n",
    "df['SMI'] = df['close'].pct_change(1)\n",
    "df.drop(df.columns[[0]], axis=1, inplace=True)  # df.columns is zero-based pd.Index \n",
    "final_df = pd.concat([final_df, df], axis=1)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in final_df.index.values:\n",
    "    if final_df.loc[i, 'SMI'] < 0 :\n",
    "        final_df.loc[i,'sig'] = 0\n",
    "    else:\n",
    "        final_df.loc[i,'sig'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.dropna(axis=0, inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['sig'] = final_df['sig'].shift(-1, axis = 0) \n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.dropna(axis=0, inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.sig = final_df.sig.astype('int64') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['eurchf', 'usdjpy','dj', 'dollind', 'eurchf', 'eurgbp', 'eurusd', 'futsee', 'gbpchf', 'gbpusd', 'light','minidj', 'minisp', 'sp', 'usdchf', 'usdjpy', 'xag', 'xau']  # a list of the feature names for later\n",
    "target = final_df['SMI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features and targets\n",
    "# use feature_names for features; '5d_close_future_pct' for targets\n",
    "features = final_df[feature_names]\n",
    "# Create DataFrame from target column and feature columns\n",
    "feature_and_target_cols = ['SMI'] + feature_names\n",
    "feat_targ_df = final_df[feature_and_target_cols]\n",
    "# Calculate correlation matrix\n",
    "corr = feat_targ_df.corr()\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap of correlation matrix\n",
    "fig, ax = plt.subplots(figsize=(10,10))  \n",
    "sns.heatmap(corr, annot= True, annot_kws = {\"size\": 12},  ax=ax, cbar_kws={\"shrink\": .9}, cmap='rocket_r', center=0, vmin=-1, vmax=1)\n",
    "plt.yticks(rotation=0, size = 14); plt.xticks(rotation=90, size = 14)  # fix ticklabel directions and size\n",
    "plt.tight_layout()  # fits plot area to the plot, \"tightly\"\n",
    "plt.show()# show the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.drop(['time','SMI'], axis=1, inplace=True)  # df.columns is zero-based pd.Index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.describe()\n",
    "plt.hist(final_df['sig'])\n",
    "plt.title('Signal (negative=0 , positive=1)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_mean=list(final_df.columns[0:11])\n",
    "# split dataframe into two based on diagnosis\n",
    "dfn=final_df[final_df['sig'] ==1]\n",
    "dfp=final_df[final_df['sig'] ==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stack the data\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(8,10))\n",
    "axes = axes.ravel()\n",
    "for idx,ax in enumerate(axes):\n",
    "    ax.figure\n",
    "    binwidth= (max(final_df[features_mean[idx]]) - min(final_df[features_mean[idx]]))/50\n",
    "    ax.hist([dfn[features_mean[idx]],dfp[features_mean[idx]]], bins=np.arange(min(final_df[features_mean[idx]]), max(final_df[features_mean[idx]]) + binwidth, binwidth) , alpha=0.5,stacked=True, density = True, label=['neg','pos'],color=['r','g'])\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_title(features_mean[idx])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = go.Pie(labels = ['pos','neg'], values = final_df['sig'].value_counts(), \n",
    "               textfont=dict(size=15), opacity = 0.8,\n",
    "               marker=dict(colors=['lightskyblue', 'gold'], \n",
    "                           line=dict(color='#000000', width=1.5)))\n",
    "\n",
    "\n",
    "layout = dict(title =  'Distribution of diagnosis variable')\n",
    "           \n",
    "fig = dict(data = [trace], layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf, testdf = train_test_split(final_df, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generic function for making a classification model and accessing the performance. \n",
    "# From AnalyticsVidhya tutorial\n",
    "def classification_model(model, data, predictors, outcome):\n",
    "  #Fit the model:\n",
    "  model.fit(data[predictors],data[outcome])\n",
    "  \n",
    "  #Make predictions on training set:\n",
    "  predictions = model.predict(data[predictors])\n",
    "  \n",
    "  #Print accuracy\n",
    "  accuracy = metrics.accuracy_score(predictions,data[outcome])\n",
    "  print(\"Accuracy : %s\" % \"{0:.3%}\".format(accuracy))\n",
    "\n",
    "  #Perform k-fold cross-validation with 5 folds\n",
    "  #kf = KFold(data.shape[0], n_folds=5)\n",
    "  #error = []\n",
    "  #for train, test in kf:\n",
    "  kf = KFold(n_splits=5)\n",
    "  error = []\n",
    "  for train, test in kf.split(traindf):\n",
    "    # Filter training data\n",
    "    train_predictors = (data[predictors].iloc[train,:])\n",
    "    \n",
    "    # The target we're using to train the algorithm.\n",
    "    train_target = data[outcome].iloc[train]\n",
    "    \n",
    "    # Training the algorithm using the predictors and target.\n",
    "    model.fit(train_predictors, train_target)\n",
    "    \n",
    "    #Record error from each cross-validation run\n",
    "    error.append(model.score(data[predictors].iloc[test,:], data[outcome].iloc[test]))\n",
    "    \n",
    "    print(\"Cross-Validation Score : %s\" % \"{0:.3%}\".format(np.mean(error)))\n",
    "    \n",
    "  #Fit the model again so that it can be refered outside the function:\n",
    "  model.fit(data[predictors],data[outcome]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression model¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold   #For K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_var = ['eurchf','usdchf','eurusd', 'gbpchf', 'xag', 'xau','minisp','minidj', 'dj', 'sp', 'light']\n",
    "outcome_var='sig'\n",
    "model=LogisticRegression()\n",
    "classification_model(model,traindf,predictor_var,outcome_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_var = ['eurchf','usdchf','eurusd', 'gbpchf', 'xag', 'xau','minisp','minidj', 'dj', 'sp', 'light']\n",
    "model = DecisionTreeClassifier()\n",
    "classification_model(model,traindf,predictor_var,outcome_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randome Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all the features of the nucleus\n",
    "predictor_var = features_mean\n",
    "model = RandomForestClassifier(n_estimators=100,min_samples_split=25, max_depth=7, max_features=2)\n",
    "classification_model(model, traindf,predictor_var,outcome_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a series with feature importances:\n",
    "featimp = pd.Series(model.feature_importances_, index=predictor_var).sort_values(ascending=False)\n",
    "print(featimp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using top 5 features\n",
    "predictor_var = ['concave points_mean','area_mean','radius_mean','perimeter_mean','concavity_mean',]\n",
    "model = RandomForestClassifier(n_estimators=100, min_samples_split=25, max_depth=7, max_features=2)\n",
    "classification_model(model,traindf,predictor_var,outcome_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_var =  ['radius_mean']\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "classification_model(model, traindf,predictor_var,outcome_var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using on the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all the features of the nucleus\n",
    "predictor_var = features_mean\n",
    "model = RandomForestClassifier(n_estimators=100,min_samples_split=25, max_depth=7, max_features=2)\n",
    "classification_model(model, testdf,predictor_var,outcome_var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## da https://towardsdatascience.com/machine-learning-for-stock-prediction-a-quantitative-approach-4ca98c0bfb8c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection\n",
    "\n",
    "310 features are a great number. It’s very useful to take only the most important ones. For this example, we’ll sort the features by the absolute value of the Pearson’s correlation coefficient of each feature and the target. The idea is to take only the 50 most correlated features to the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = np.abs(X_train.corrwith(y_train))\n",
    "features =  list(correlations.sort_values(ascending=False)\n",
    "                 [0:50].index)\n",
    "X_train = X_train[features]\n",
    "X_test = X_test[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start with the models.\n",
    "Linear regression\n",
    "\n",
    "Let’s start with the simplest regression model ever, which is the linear regression.\n",
    "\n",
    "First, we’ll train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we calculate the predictions of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions can be compared with the real test set data to calculate the prediction error. For this example, I’ll use the mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error is 1.325\n",
    "\n",
    "We can finally plot the real values of the test set and the predicted value to check if they lie in a 45° line passing through 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,y_pred)\n",
    "plt.xlabel(\"Real\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Linear regression\")plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, real and predicted values are pretty similar.\n",
    "Random forest\n",
    "\n",
    "The next model is a Random Forest Regressor from sklearn library.\n",
    "\n",
    "Since Random Forest model has many hyperparameters, it’s useful to fine-tune them by a random search. The hyperparameters we are going to tune are the number of trees and the number of features.\n",
    "\n",
    "We’ll perform a 20 steps random search with a 5-fold cross-validation, calculating the mean absolute error for each fold and then averaging among the 5 folds. The hyperparameters’ values that minimize the error (i.e. maximize the error with the minus sign) are the optimal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomizedSearchCV(RandomForestRegressor(),\n",
    "param_distributions =  {\n",
    "                  'n_estimators':np.arange(10,500,5),\n",
    "                  'max_features':np.arange(1,10,1)\n",
    "               },\n",
    "                  cv=5, n_iter = 20,\n",
    "                  iid=False,random_state=0,refit=True,\n",
    "                  scoring=\"neg_mean_absolute_error\")\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best values for the hyperparameters are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean absolute error, calculated with the same code used for the linear regression, is 0.868\n",
    "\n",
    "This is the scatter plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest shows a lower error than linear regression.\n",
    "Gradient boosting tree regressor\n",
    "\n",
    "We can now try with the Gradient Boosting tree regressor, which uses the boosting technique to improve model accuracy.\n",
    "\n",
    "We still have two hyperparameters, which are the number of trees used in the boosting sequence and the maximum number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = RandomizedSearchCV(GradientBoostingRegressor(),\n",
    "param_distributions =  {\n",
    "               'n_estimators':np.arange(10,500,5),\n",
    "               'max_features':np.arange(1,10,1)\n",
    "            },\n",
    "          cv=5, n_iter = 20,\n",
    "          iid=False,random_state=0,refit=True,\n",
    "          scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "gb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K nearest neighbors\n",
    "\n",
    "KNN is a very powerful model in many application and we’ll use it in this example. We’ll change the nearest neighbors from 1 to 20 and the scoring formula from “uniform” (each neighbor has the same weight) to “distance” (each neighbor is weighted by the inverse of the distance between it and the input vector).\n",
    "\n",
    "Since this hyperparameter space is quite small, we can easily use a grid search instead of a random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = GridSearchCV(KNeighborsRegressor(),\n",
    "param_grid =  {\n",
    "            'n_neighbors':np.arange(1,20,1),\n",
    "            'weights':['distance','uniform']\n",
    "            },\n",
    "          cv=5, \n",
    "          iid=False,refit=True,\n",
    "          scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network\n",
    "\n",
    "We’ll finish our model scouting with a single-layer Artificial Neural Network, with 5000 maximum epochs, an adaptive learning rate, and using the Stochastic Gradient Descent optimization algorithm.\n",
    "\n",
    "Our hyperparameters are the number of neurons of the hidden layer (which we’ll span from 1 to 50) and their activation function (which will span among logistic and ReLU).\n",
    "\n",
    "Before giving training data to an ANN we must scale them. We’ll use a MinMaxScaler to scale each feature into the 0–1 interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()scaler.fit(X_train)nnet = RandomizedSearchCV(MLPRegressor(max_iter=5000,learning_rate = 'adaptive',solver='sgd'),\n",
    "param_distributions =  {\n",
    "     'hidden_layer_sizes':[(x,) for x in np.arange(1,50,1)],\n",
    "     'activation':['logistic','relu']\n",
    "},\n",
    "cv=5, n_iter = 20,\n",
    "iid=False,random_state=0,refit=True,\n",
    "scoring=\"neg_mean_absolute_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## migliore modello knn ma migliorando linear regression...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best result performed so far has been achieved by the Linear Regression with bagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
